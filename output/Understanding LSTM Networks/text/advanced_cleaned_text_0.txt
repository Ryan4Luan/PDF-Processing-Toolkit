August 27, 2015 Recurrent Neural Networks one the last few years Andrej Karpathyâ€™s The Unreasonable Effectiveness of Recurrent Neural Networks Understanding LSTM Networks Posted on   Humans dont start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You dont throw everything away and start thinking from scratch again. Your thoughts have persistence. Traditional neural networks cant do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. Its unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones. Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.    have loops. In the above diagram, a chunk of neural network, A, looks at some input a and outguts a value h. A loop allows information to be passed from  step of the network to the next. These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they arent all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop h Gip . fh. ta bo  An unrolled recurrent neural network. __  This chainlike nature reveals that recurrent neural networks are intimately related to sequences and lists. Theyre the, natural architecture of neural network to use for such data. And they certainly are used In , there have been incredible success applying RNNs to a variety of problems speech recognition, language modeling, translation, image captioning... The list goes on. Ill leave discussion of the amazing feats  can achieve with RNNs to  excellent blog post,  . But they really are pretty amazing.